# CPSC 393 Extra Learning Resources

## Books (Optional)

These books are some of my favorite references for the topics we cover. These are books I use when prepping our lectures, and have served me well in grad school and beyond!

- [Introduction to Statistical Learning with Applications in R (ISLR)](https://www.statlearning.com/)
- [The Elements of Statistical Learning (ESL)](https://hastie.su.domains/Papers/ESLII.pdf)
- [Deep Learning](https://www.deeplearningbook.org/)
- [Pattern Recognition and Machine Learning](https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738)
- [Mathematics for Machine Learning](https://mml-book.github.io/book/mml-book.pdf)
- [Probabilistic Machine Learning](https://probml.github.io/pml-book/)

## Course Topics

Videos, blogs, and articles that cover topics we talk about in class.

### Math and Data Science Review
- [3B1B: Taylor Series](https://youtube.com/watch?v=3d6DsjIBzJ4)
- [Common Taylor Series](https://people.math.sc.edu/girardi/m142/handouts/10sTaylorPolySeries.pdf)
- [Count Bayesie: KL Divergence](countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)
- [Khan Academy: Lagrange Multipliers and Constrained Optimization](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint)
- [StatQuest The ChainRule](https://youtu.be/wl1myxrtQHQ)


### SVM
- [CodeEmporium: The Kernel Trick - THE MATH YOU SHOULD KNOW!](https://www.youtube.com/watch?v=wBVSbVktLIY)
- [StatQuest SVM Playlist](https://www.youtube.com/playlist?list=PLblh5JKOoLUL3IJ4-yor0HzkqDQ3JmJkc)
- [Lagrangian Formulation of SVMs](http://sfb649.wiwi.hu-berlin.de/fedc_homepage/xplore/tutorials/stfhtmlnode64.html)
- [Kernel Methods (book chapter)](https://people.eecs.berkeley.edu/~jordan/kernels/0521813972c02_p25-46.pdf)


### Neural Networks and Optimization
- [e2ml: Softmax Activation](https://e2eml.school/softmax.html)
- [Keras Optimizers](https://www.kaggle.com/code/residentmario/keras-optimizers/notebook)
- [Neural Networks are Decision Trees](https://arxiv.org/pdf/2210.05189.pdf)
- [StatQuest Neural Networks](https://youtu.be/CqOfi41LfDw)
- [StatQuest Backpropagation Main Ideas](https://youtu.be/IN2XmBhILt4)
- [StatQuest Backpropagation Details Pt 1:](https://youtu.be/iyn2zdALii8)
- [StatQuest Backpropagation Details Pt 2:](https://youtu.be/GKZoOHXGcLo)
- [StatQuest ReLU](https://youtu.be/68BZ5f7P94E)
- [3Blue1Brown Neural Network Playlist](https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- [Code Emporium: Gradient Descent, the Math You Should Know](https://youtu.be/-p1ldISb90Q)
- [Machine Learning University: Double Descent A Visual Introduction](https://mlu-explain.github.io/double-descent/)
- [Geeks for Geeks: Intuition of Adam Optimizer](https://www.geeksforgeeks.org/intuition-of-adam-optimizer/)
- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)
- [Code Emporium: Optimizers](https://www.youtube.com/watch?v=mdKjMPmcWjY)
- [Ruder.io: An Overview of Gradient Descent Optimization Algorithms](https://www.ruder.io/optimizing-gradient-descent/#challenges)
- [Louis Tiao: Visualizing and Animating Optimization Algorithms with Matplotlib](http://louistiao.me/notes/visualizing-and-animating-optimization-algorithms-with-matplotlib/)
- [Machine Learning Mastery: Adam Optimizer from Scratch](https://machinelearningmastery.com/adam-optimization-from-scratch/)
- [Three Ways to Build Machine Learning Models in Keras](https://machinelearningmastery.com/three-ways-to-build-machine-learning-models-in-keras/)
- [Kernel, Bias and Activity RegulizerL what, when, and why](https://www.linkedin.com/pulse/kernel-bias-activity-regularizer-what-when-why-chiranjit-pathak)
- [StackOverflow: What is the difference between Kernel, Bias, and Activity Regulizers?](https://stats.stackexchange.com/questions/383310/what-is-the-difference-between-kernel-bias-and-activity-regulizers-and-when-t)

### Convolutional Neural Networks
- [3Blue1Brown What is Convolution?](https://youtu.be/KuXjwB4LzSA)
- [A Review of Different Interpretation Methods in CNNs](https://mrsalehi.medium.com/a-review-of-different-interpretation-methods-in-deep-learning-part-1-saliency-map-cam-grad-cam-3a34476bc24d)
- [Skip Connections](https://theaisummer.com/skip-connections/)
- [Code Emporium: Convolutional Neural Networks Explained!](https://youtu.be/m8pOnJxOcqY)
- [CS231n Convolutional Neural Network Notes](https://cs231n.github.io/convolutional-networks/)
- [Geeks for Geeks: Depthwise Separable Convolutions](https://www.geeksforgeeks.org/depth-wise-separable-convolutional-neural-networks/)

### Recurrent Neural Networks
- [StatQuest: Recurrent Neural Networks Clearly Explained](https://youtu.be/AsNTP8Kwu80)
- [Michael Phi: Illustrated Guide to Recurrent Neural Networks](https://www.youtube.com/watch?v=LHXXI4-IEns)

### LSTMs and GRUs
- [Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [Gated Recurrent Units](https://d2l.ai/chapter_recurrent-modern/gru.html)
- [LSTMs with PyTorch](https://www.youtube.com/watch?v=RHGiXPuo_pI)
- [StatQuest LSTM's Clearly Explained](https://www.youtube.com/watch?v=YCzL96nL7j0)
- [Code Emporium: LSTM Networks Explained!](https://youtu.be/QciIcRxJvsM)

### Transformers
- [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
- [e2ml: Transfomers from Scratch](https://e2eml.school/transformers.html)
- [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [The Transformer Architechture: The Positional Encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)
- [Attentional Neural Network Models](https://www.youtube.com/watch?v=rBCqOTEfxvg)
- [Neural machine translation with a Transformer and Keras](https://www.tensorflow.org/text/tutorials/transformer)
- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
- [Code Emporium: Transformer NNs an Overview](https://youtu.be/O3xbVmpdJwU)

### Generative Models
- [Tutorial on Variational AutoEncoders](https://arxiv.org/abs/1606.05908)
- [Tensorflow: Deep Convolutional GAN](https://www.tensorflow.org/tutorials/generative/dcgan)
- [Code Emporium: GANs](https://youtu.be/O8LAi6ksC80)
- [Computerphile: How AI Image Generators Work (Stable Diffusion/ DALL-E)](https://www.youtube.com/watch?v=1CIpzeNxIhU)

### Other
- [The Illustrated word2vec](https://jalammar.github.io/illustrated-word2vec/)
- [Human-Like Playtesting with Deep Learning (Candy Crush)](https://ieeexplore.ieee.org/document/8490442)
- [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)
- [Pervasive Attention: 2D Convolutional Neural Networks for Sequence-to-Sequence Prediction](https://arxiv.org/abs/1808.03867)

### Data Sources
- [Sebastian Raschka: Datasets for DL and ML](https://sebastianraschka.com/blog/2021/ml-dl-datasets.html)
- [Kaggle](https://www.kaggle.com/datasets)