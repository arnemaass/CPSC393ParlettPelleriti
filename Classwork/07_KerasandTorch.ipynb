{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvT_MsRiAt6s"
      },
      "outputs": [],
      "source": [
        "# data packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
        "from sklearn.model_selection import train_test_split # simple TT split cv\n",
        "\n",
        "# keras + torch\n",
        "from keras.datasets import mnist\n",
        "import keras as kb\n",
        "import torch\n",
        "\n",
        "# set up torch backend\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZA76RVpAt6u"
      },
      "source": [
        "# Basic Torch Operations\n",
        "\n",
        "While we'll often be using the neural network specific parts of Torch (or using it through Keras), it's good to know what's going on \"under the hood\" so let's look at how Torch represents tensors, and how we can use them.\n",
        "\n",
        "\n",
        "First we'll look at a few ways to create a torch tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGFwGWUmAt6v"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(size=(2, 2))"
      ],
      "metadata": {
        "id": "cN7fuSddrTlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(size=(2, 1))"
      ],
      "metadata": {
        "id": "hhBQyZ-crUtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(2,1))"
      ],
      "metadata": {
        "id": "Nvmr_X0ZrVpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.reshape(x,(-1,))\n",
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3EmiiIjrOPx",
        "outputId": "0095d76e-0275-40b1-e4d1-50bc3a0ff02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll look at some matrix operations we can do using tensors."
      ],
      "metadata": {
        "id": "bMv3OiJ_pwAT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-ee34R6At6w",
        "outputId": "fd6ea204-dc69-4825-dda6-946d64593aca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2726, 0.3048])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "torch.square(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y72LJYqaAt6x",
        "outputId": "4c355ddb-1271-44fc-cb9a-35bbfc613115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7226, 0.7430])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "torch.sqrt(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzbRnTD7At6x",
        "outputId": "cfd357a7-980b-48b5-d3cb-22ddbb2ebd44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5221, 1.5521],\n",
              "        [1.5221, 1.5521]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "y = torch.ones(size = (2,1))\n",
        "\n",
        "x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0Qwk8VbAt6y",
        "outputId": "9c75f8b4-44b3-4b8a-f742-f36297ef4832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9812, 0.4960])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "z = torch.rand(size = (2,2))\n",
        "torch.matmul(z,x) #2x2 * 2*1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpoNxocnqmjQ",
        "outputId": "8c31f6fc-6e15-45d1-fca5-ed76a796efc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ongSvnh9At60"
      },
      "source": [
        "# Gradients (the reason we're all here)\n",
        "\n",
        "So far, Torch is looking a lot like a fancy numpy. But it's a lot more than that. Torch allows us to very easily calculate and track gradients, and use them to update parameters in our model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNCvuzS9At61"
      },
      "source": [
        "# Linear Regression with Torch\n",
        "\n",
        "Here we'll build a Linear Regression Model from scratch using JUST PyTorch. Let's look at the code to see how it works (luckily we won't often do this):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ljm5f8xAt61"
      },
      "outputs": [],
      "source": [
        "# generate data\n",
        "X = torch.arange(-5, 5, 0.1).view(-1, 1) #.view() reshapes our data to be an array with a single dimension\n",
        "# X.size()\n",
        "\n",
        "# coefficient is -6, intercept is 4\n",
        "Y = 4 + -6 * X + 0.2 * torch.randn(X.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll define two functions: `forward` and `loss` which define what a forward pass (prediction) of the model, and the loss function for the model (MSE), respectively."
      ],
      "metadata": {
        "id": "oIMXoFXfCEo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a forward pass is how we use the model to make a prediction\n",
        "def forward(x):\n",
        "    return w * x + b\n",
        "\n",
        "# define a loss function, in this case MSE\n",
        "def loss(y_pred, y):\n",
        "    return torch.mean((y_pred - y) ** 2)"
      ],
      "metadata": {
        "id": "mk6MNzaJD9QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we'll define torch `tensor` objects that will store and track our different model parameters (`w` the coefficient for our model, and `b` the intercept/bias of the model).\n",
        "\n",
        "Next, we'll set a few parameters:\n",
        "\n",
        "- `step_size`: this determines the size of the adjustment we're making to our parameters at each update (remember: $w_{new} = w_{old} - \\alpha * g$)\n",
        "- `loss_list`: a list to store our loss history, so we can plot it later\n",
        "- `iter`: the number of updates to make to our parameters"
      ],
      "metadata": {
        "id": "5WvOJwHFCrqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(-10.0, requires_grad=True) # create a tensor to store our coefficient, set it to -10 initially\n",
        "b = torch.tensor(-20.0, requires_grad=True) # create a tensor to store our intercept, set it to -20 initially\n",
        "\n",
        "\n",
        "# how BIG of an adjustment should we make to w and b each step\n",
        "step_size = 0.1\n",
        "\n",
        "# track loss over time\n",
        "loss_list = []\n",
        "\n",
        "# number of steps\n",
        "iter = 100"
      ],
      "metadata": {
        "id": "CgZsE1U6EE9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll use a `for` loop to actually run our updates.\n",
        "\n",
        "We will:\n",
        "\n",
        "1. do a forward pass (make a prediction using current weights)\n",
        "2. calculate the loss from those predictions\n",
        "3. store the loss\n",
        "4. do a packward pass (calculate the gradients)\n",
        "5. update our parameters, `w` and `b`\n",
        "6. zero out our gradients so we can start over on the next iteration"
      ],
      "metadata": {
        "id": "xVP3WJhRDkjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(iter):\n",
        "  # 1. making predictions\n",
        "  Y_pred = forward(X)\n",
        "\n",
        "  # 2. calculating the loss\n",
        "  loss_val = loss(Y_pred, Y)\n",
        "\n",
        "  # 3. storing the calculated loss in a list\n",
        "  loss_list.append(loss_val.item())\n",
        "\n",
        "  # 4. backward pass for computing the gradients of the loss w.r.t to w and b\n",
        "  loss_val.backward()\n",
        "\n",
        "  # 5. update the w/b\n",
        "  w.data = w.data - step_size * w.grad.data\n",
        "  b.data = b.data - step_size * b.grad.data\n",
        "\n",
        "  # 6. zeroing gradients after each iteration\n",
        "  w.grad.data.zero_()\n",
        "  b.grad.data.zero_()\n",
        "\n",
        "  # priting the values for understanding\n",
        "  print('iter: {}, \\tloss: {}, \\tcoef: {}, \\tinterc: {}'.format(i, loss_val.item(), w.item(), b.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL8KtImvEc52",
        "outputId": "4f19d356-bd3c-4347-a39d-0cd32dc1cbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 1, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 2, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 3, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 4, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 5, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 6, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 7, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 8, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 9, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 10, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 11, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 12, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 13, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 14, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 15, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 16, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 17, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 18, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 19, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 20, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 21, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 22, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 23, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 24, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 25, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 26, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 27, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 28, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 29, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 30, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 31, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 32, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 33, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 34, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 35, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 36, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 37, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 38, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 39, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 40, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 41, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 42, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 43, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 44, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 45, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 46, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 47, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 48, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 49, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 50, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 51, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 52, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 53, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 54, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 55, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 56, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 57, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 58, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 59, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 60, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 61, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 62, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 63, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 64, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 65, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 66, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 67, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 68, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 69, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 70, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 71, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 72, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 73, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 74, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 75, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 76, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 77, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 78, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 79, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 80, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 81, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 82, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 83, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 84, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 85, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 86, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 87, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 88, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 89, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 90, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 91, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 92, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 93, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 94, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 95, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 96, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 97, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 98, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n",
            "iter: 99, \tloss: 0.04759201034903526, \tcoef: -6.009518146514893, \tinterc: 4.005242824554443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last, we'll plot our loss over time. Notice we converge on the true values quite quickly!"
      ],
      "metadata": {
        "id": "sh_d-bWnELmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_list, 'r')\n",
        "plt.grid('True', color='grey')\n",
        "plt.xlabel(\"Epochs/Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "7zuzRy8wFK6r",
        "outputId": "0db794f3-67b0-4b4b-96d2-b2262d1855b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vPRe7X2At62"
      },
      "source": [
        "# Basic Keras Compnents\n",
        "\n",
        "Now that we've seen how pyTorch works \"under the hood\", let's see how we can use Keras (with a pyTorch backend) to create neural networks.\n",
        "\n",
        "There are 3 main ways we'll interact with the Keras package: Using **`Sequential()`** (which is what we've done up to this point), using the **Functional API**, and **Subclassing** the `Model` class.\n",
        "\n",
        "## Model Objects\n",
        "- `Model()`: an object that groups layers together to be trained and to make predictions\n",
        "\n",
        "\n",
        "With `Model()` objects we can either use the **Functional API** to interface with them, or we can **subclass** the `Model()` object.\n",
        "\n",
        "### Functional API\n",
        "Here, we treat layers as functions that have input tensors and output tensors. Each layer takes in the output from the previous layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESaBudIIAt62",
        "outputId": "4840a563-8b84-4109-bce9-bbe7e8d6b252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 25)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                260       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 12        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330 (1.29 KB)\n",
            "Trainable params: 330 (1.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Functional API building\n",
        "\n",
        "inputs = kb.Input(shape = (25,))\n",
        "\n",
        "x = kb.layers.Dense(10)(inputs)\n",
        "\n",
        "x = kb.layers.Dense(5)(x)\n",
        "\n",
        "x = kb.layers.Dense(2)(x)\n",
        "\n",
        "outputs = kb.layers.Dense(1, activation = kb.activations.relu)(x)\n",
        "\n",
        "model = kb.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiufisk0At62"
      },
      "source": [
        "Or we can create a new class that inherits from `Model()`.\n",
        "\n",
        "First we create a class that inherets from `kb.Model`, and then we create an `__init__` method that first calls the superclass' `__init__()` and then defines every layer that we need. We want this to happen in the constructor, otherwise the layers might be created more than once (which we do not want).\n",
        "\n",
        "Then we create a `call()` method which basically defines what a forward pass of your model looks like. It takes in the default `self` arugment as well as some input to the model. This looks similar to how we defined things using the Functional API. Then we return the output of the model.\n",
        "\n",
        "Now we can use this subclass to build a model!\n",
        "- We create inputs\n",
        "- We put those inputs into our model object\n",
        "- We put both into a `Model()` object\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk-qE5DuAt63",
        "outputId": "cbbed0c3-ef4a-41dc-a5bc-1fac47a24f99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 25)]              0         \n",
            "                                                                 \n",
            " my_model (MyModel)          (None, 1)                 330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330 (1.29 KB)\n",
            "Trainable params: 330 (1.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# we won't do this often but its nice to know\n",
        "\n",
        "class MyModel(kb.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        # call init from inhereted class\n",
        "        super().__init__()\n",
        "\n",
        "        # create all layers here so they're only created once\n",
        "        self.layer1 = kb.layers.Dense(10, input_shape = [25])\n",
        "        self.layer2 = kb.layers.Dense(5)\n",
        "        self.layer3 = kb.layers.Dense(2)\n",
        "        self.layer4 = kb.layers.Dense(1, activation = \"sigmoid\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # define what a forward pass looks like\n",
        "        x = self.layer1(inputs)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        return(self.layer4(x))\n",
        "\n",
        "# define input shape\n",
        "inputs = kb.Input(shape = (25,))\n",
        "\n",
        "# create a model using your custom class\n",
        "x = MyModel()(inputs)\n",
        "\n",
        "# shove the inputs and outputs into a model object\n",
        "my_model = kb.Model(inputs = inputs, outputs = x)\n",
        "\n",
        "# show me the model\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lIpSLHGAt63"
      },
      "source": [
        "## Sequential Object\n",
        "\n",
        "- `Sequential()`: an object that groups layers together in a linear stack (less flexible than `Model` but typically all we need)\n",
        "\n",
        "This is what we've done so far (and what we did in CPSC 392). We create a `Sequential()` object and give it a list of layers to add (in order).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nXzqn88At63",
        "outputId": "febbf7c6-ccb8-4537-f427-0e52be332d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                260       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2)                 12        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330 (1.29 KB)\n",
            "Trainable params: 330 (1.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# give Sequential a list of layers\n",
        "my_model = kb.Sequential([\n",
        "    kb.layers.Dense(10, input_shape = [25]),\n",
        "    kb.layers.Dense(5),\n",
        "    kb.layers.Dense(2),\n",
        "    kb.layers.Dense(1, activation = \"sigmoid\")\n",
        "])\n",
        "\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-XCO5tjAt63"
      },
      "source": [
        "If we want to add layers dynamically, we can use `.add()` and `.pop()` to add and pop layers on/off our model. This would be useful, for example, if we wanted to loop through a list of values and add layers with those values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVmWhNuWAt63",
        "outputId": "3e7c7bae-1134-48c3-f347-e861c5b84e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 10)                260       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 12        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330 (1.29 KB)\n",
            "Trainable params: 330 (1.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# use .add() to dynamically add layers\n",
        "my_model = kb.Sequential()\n",
        "my_model.add(kb.layers.Dense(10, input_shape = [25]))\n",
        "my_model.add(kb.layers.Dense(5))\n",
        "my_model.add(kb.layers.Dense(2))\n",
        "my_model.add(kb.layers.Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS0P_sYcAt64"
      },
      "source": [
        "\n",
        "## Layers\n",
        "Keras has many pre-defined layers that we can use (we'll learn about more of them as we learn about more model structures). For now the important layers are:\n",
        "\n",
        "- `Dense()`: A basic densely connected layer with `units` nodes. Densely connected means that every node in the previous layer is connected to every node in the current layer.\n",
        "- `Activation()`: applies an activation function (defined by the `activation` argument) to the values coming into it. This is largely the same as using the `activation` argument in a `Dense` Layer but is useful when you want to do an operation to the layer output BEFORE applying the activation (e.g. `BatchNormalization`)\n",
        "- `Input()`: A basic layer that defined the input of a model. It tells the model what the initial tensor of data that we expect to come in looks like. The `shape` argument tells the model what a *single sample* of data looks like (not a batch of samples)\n",
        "\n",
        "\n",
        "`Dense` Layers tend to be the basis of most of our Neural Networks, so let's get to know the documentation a little!\n",
        "\n",
        "- **Question** look at the [documentation](https://keras.io/api/layers/core_layers/dense/) for `Dense` layers. If I wanted to NOT have a bias for that layer, how might I tell python that?\n",
        "- **Question** look at the [documentation](https://keras.io/api/layers/core_layers/dense/) for `Dense` layers. If you do not supply a value for `activation` what activation does it use?\n",
        "\n",
        "\n",
        "There are many activation functions (or you can even define your own), let's look at the `activation` documentation and see what's available:\n",
        "\n",
        "- **Question** look at the [documentation](https://keras.io/api/layers/activations/) for `activations`. What basic activation functions are available?\n",
        "- Modify the code below to add a `ReLu` activation to the middle layer (either using the `activation` argument in `Dense()` or by adding an `Activation()` layer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMiyaUSVAt64",
        "outputId": "a4043d5e-0634-489f-83aa-3b3077eaed25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 10)                260       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 2)                 12        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330 (1.29 KB)\n",
            "Trainable params: 330 (1.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "### YOUR CODE HERE ###\n",
        "activated_model = kb.Sequential([\n",
        "    kb.Input(shape = [25]),\n",
        "    kb.layers.Dense(10),\n",
        "    kb.layers.Dense(5), # add relu here\n",
        "    kb.layers.Dense(2),\n",
        "    kb.layers.Dense(1, activation = \"sigmoid\")\n",
        "])\n",
        "\n",
        "activated_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHgS7YI8At64"
      },
      "source": [
        "## Try It Out\n",
        "Build a model with the following structure in 3 different ways:\n",
        "\n",
        "- input size of 9\n",
        "- 2 hidden layers (with 7 and 3 nodes respectively) and `relu` activations\n",
        "- output layer with 1 node and a sigmoid activation\n",
        "\n",
        "1. Build the model using a basic `Sequential()` object and using `.add()` to add each layer. Set the activation(s) using an `Activation()` layer.\n",
        "2. Build the model using the Functional API method with `Model()`. Set the activation(s) using the `activation` argument in each layer where necessary.\n",
        "3. Build the model by subclassing `Model()`. Build all your layers in the `__init__()` method, and define a forward pass using your `call()` method. Then use the class to build your model. Set the activation(s) using the `activation` argument in each layer where necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh9htRyrAt64"
      },
      "outputs": [],
      "source": [
        "# 1. `Sequential()`\n",
        "\n",
        "my_model1 = kb.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQx9sPFFAt64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "2c9723b3-edf3-4ba3-bb2d-a8cbc4e28c55"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-20-16fa721ef4ad>, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-16fa721ef4ad>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    outputs = ???\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# 2. Functional API\n",
        "\n",
        "inputs = kb.Input()\n",
        "\n",
        "# stuff\n",
        "\n",
        "outputs = ???\n",
        "\n",
        "my_model2 = kb.Model(inputs = inputs, outputs = outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svqUIPwbAt65"
      },
      "outputs": [],
      "source": [
        "# 3. Subclass\n",
        "\n",
        "class MyModel(kb.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # layers\n",
        "        pass\n",
        "\n",
        "    def call(self, inputs):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9CYm3n0At65"
      },
      "source": [
        "## Functions\n",
        "\n",
        "We've already used all these functions, but as a quick refresher:\n",
        "\n",
        "- `.summary()`: call it on a model to see the structure of the model as well as information about they layers\n",
        "- `.compile()`: tells python *how* to train your model, e.g. which optimizer to use, which metrics to collect, what your test/validation set is.\n",
        "- `.fit()`: train your model given the data (input and output), number of `epochs`, etc (just like sklearn but with more options)\n",
        "- `.predict()`: use your model to make predictions given some input values (just like sklearn)\n",
        "\n",
        "\n",
        "\n",
        "If you have time, download [this data set](https://www.kaggle.com/datasets/chaunguynnghunh/sepsis?select=Paitients_Files_Train.csv) and train one or all of the models you built on it (Don't include `ID` as a predictor). Don't forget to z-score and to use [`LabelBinarizer()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) to change the outputs to 0's and 1's. Use whatever optimizer you want."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}